{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5574TzIrQ4Y_",
        "outputId": "2bd1050a-c96d-4aae-b3da-822836e03c60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import TFGPT2LMHeadModel"
      ],
      "metadata": {
        "id": "U7MzFh9NQ6F2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TFGPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2', from_pt=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx2G10slQ6Iv",
        "outputId": "b988308b-0fb3-4e34-933e-7111c60e262a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2LMHeadModel: ['transformer.h.4.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'lm_head.weight', 'transformer.h.11.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.9.attn.masked_bias']\n",
            "- This IS expected if you are initializing TFGPT2LMHeadModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFGPT2LMHeadModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent = '학점을 잘 받기 위해서는'"
      ],
      "metadata": {
        "id": "MRTL5y7jQ6LD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(sent)\n",
        "input_ids = tf.convert_to_tensor([input_ids])\n",
        "print(input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tI6b-VtzQ6Mr",
        "outputId": "eda9e483-d5ec-4922-c614-38dcc3ac4a16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[ 9245 10468  9443 19223 11357]], shape=(1, 5), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model.generate(input_ids,\n",
        "                        max_length=128,\n",
        "                        repetition_penalty=2.0,\n",
        "                        use_cache=True)\n",
        "output_ids = output.numpy().tolist()[0]\n",
        "print(output_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZeYSZ7vRLgB",
        "outputId": "950d956c-0db1-4d39-bb5a-6f0cff46e9f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9245, 10468, 9443, 19223, 11357, 11488, 14135, 8191, 10007, 20305, 7991, 9178, 20963, 9240, 10023, 10017, 34072, 9517, 10655, 9241, 11909, 9207, 34765, 11018, 9119, 11686, 9097, 11280, 9306, 37348, 9518, 9267, 9650, 13903, 11864, 9355, 9745, 34350, 35033, 9800, 8711, 11213, 11915, 15918, 29631, 10284, 29964, 9199, 15177, 8042, 10546, 46143, 10364, 20661, 12201, 11132, 9863, 50621, 15570, 32075, 20289, 9148, 10507, 9685, 9337, 9257, 26421, 387, 9025, 7166, 13124, 9023, 10586, 29230, 19850, 25970, 21159, 9022, 47340, 9415, 10912, 11004, 16364, 10805, 16337, 14554, 23813, 6932, 27827, 25181, 8705, 13447, 14908, 7335, 8704, 25978, 9137, 9956, 11274, 25085, 10704, 9105, 8703, 8033, 12031, 11290, 31234, 9030, 9882, 14422, 9430, 33253, 38457, 12819, 9484, 8400, 9788, 9029, 8146, 7397, 7532, 10152, 20967, 8186, 12384, 20883, 10252, 8095]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(output_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "BgjXNvuARkNM",
        "outputId": "9ff31108-b567-4fcf-a7c9-b4a2f4a71653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'학점을 잘 받기 위해서는 반드시 영어점수를 높여야 한다.\\n영어 점수가 높은 학생들은 대부분 대학 입시를 위해 영어를 공부한다.\\n하지만 영어는 다른 과목보다 더 중요한 요소이기 때문에 자신의 실력을 객관적으로 평가해보고 그에 맞는 전략을 세워나가는 것이 중요하다.\\n영어를 잘하는 학생이라면 우선 자신이 어떤 과목을 얼마나 공부하고 있는지부터 파악해야 할 것이다.\\n특히, 수능시험에서 좋은 성적을 거둔 학생들이 있다면 그 학생은 자신감을 갖고 꾸준히 노력한다면 충분히 상위권 대학에 진학할 가능성이 높다.\\n또한 외국어 실력이 뛰어난 학생들을 보면 어학연수와 해외연수 등 다양한 기회를 통해 글로벌 마인드를 갖출 수도 있다.\\n이러면 자기주도적 학습능력을 키울'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(input_ids)\n",
        "top5 = tf.math.top_k(output.logits[0, -1], k=5)"
      ],
      "metadata": {
        "id": "7oI-5DHlRkK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_ids_to_tokens(top5.indices.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kX8aR4xgRj_s",
        "outputId": "1604ea1b-9cea-451e-c077-2680b58505df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁반드시', '▁학', '▁자신의', '▁우선', '▁무엇보다']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent = '학점을 잘 받기 위해서는'\n",
        "input_ids = tokenizer.encode(sent)\n",
        "\n",
        "while len(input_ids) < 50:\n",
        "    output = model(np.array([input_ids]))\n",
        "    # Top 5의 단어들을 추출\n",
        "    top5 = tf.math.top_k(output.logits[0, -1], k=5)\n",
        "    # Top 5의 단어들 중 랜덤으로 다음 단어로 선택.\n",
        "    token_id = random.choice(top5.indices.numpy())\n",
        "    input_ids.append(token_id)\n",
        "\n",
        "tokenizer.decode(input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "wq6cb4EeRuL2",
        "outputId": "cd935a61-21a6-4425-83bb-322235d9782f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'학점을 잘 받기 위해서는 자신의 성적과 비교해야 한다.\\n성적이 낮더라도 자신의 성적보다 자신이 잘하는 분야에서 좋은 점수로 커나갈 확률이 더 높은 경우가 많다.\\n또 자신의 성적이나 비교하는 것은 자기만의 독특한 경험으로 자기 자신에 대해서 다른 사람들의 관심을 끌'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}